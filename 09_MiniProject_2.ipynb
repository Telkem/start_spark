{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a01186a5-55ff-4282-8f3d-60d6523cf339",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"miniproject1\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89b1d632-fd00-4ae6-9487-4625056e5e96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'file:////home/jovyan/work/start_spark/learning_spark_data/Crop_recommendation.csv'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "cwd = os.getcwd()\n",
    "trip_data_path = os.path.join(cwd, 'learning_spark_data/Crop_recommendation.csv')\n",
    "trip_data_path\n",
    "file_path = f\"file:///{trip_data_path.replace(os.sep, '/')}\"\n",
    "file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42f408c6-558a-4a5d-a393-3c79a80132c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- N: integer (nullable = true)\n",
      " |-- P: integer (nullable = true)\n",
      " |-- K: integer (nullable = true)\n",
      " |-- temperature: double (nullable = true)\n",
      " |-- humidity: double (nullable = true)\n",
      " |-- ph: double (nullable = true)\n",
      " |-- rainfall: double (nullable = true)\n",
      " |-- label: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(file_path, inferSchema=True, header=True)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6c81662-cc89-4f16-b48a-d2bb5500e9d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+-----------+-----------+-----------------+-----------+-----+\n",
      "|  N|  P|  K|temperature|   humidity|               ph|   rainfall|label|\n",
      "+---+---+---+-----------+-----------+-----------------+-----------+-----+\n",
      "| 90| 42| 43|20.87974371|82.00274423|6.502985292000001|202.9355362| rice|\n",
      "| 85| 58| 41|21.77046169|80.31964408|      7.038096361|226.6555374| rice|\n",
      "| 60| 55| 44|23.00445915| 82.3207629|      7.840207144|263.9642476| rice|\n",
      "| 74| 35| 40|26.49109635|80.15836264|      6.980400905|242.8640342| rice|\n",
      "| 78| 42| 42|20.13017482|81.60487287|      7.628472891|262.7173405| rice|\n",
      "+---+---+---+-----------+-----------+-----------------+-----------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94543c56-8e5c-4a4b-a042-fa6569be5cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+-----------+--------+---+--------+-----+\n",
      "|  N|  P|  K|temperature|humidity| ph|rainfall|label|\n",
      "+---+---+---+-----------+--------+---+--------+-----+\n",
      "|  0|  0|  0|          0|       0|  0|       0|    0|\n",
      "+---+---+---+-----------+--------+---+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, sum, when, isnan\n",
    "null_counts = df.select(\n",
    "                    [\n",
    "                        sum(when(col(c).isNull() | isnan(c), 1).otherwise(0)).alias(c)\n",
    "                        for c in df.columns\n",
    "                    ]\n",
    "                )\n",
    "null_counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d1f63189-adbc-46e6-9b72-05b6849bd531",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer, OneHotEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60718792-8307-4b5a-b929-dc6ab619dbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = df.randomSplit([0.8,0.2], seed=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06cb8ca4-b46b-48ca-8e82-559d0cf47ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "stages = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ca72ed2-61fa-4fcb-8192-5a2d48661c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelIndexer = StringIndexer(inputCol='label',outputCol = 'labelIndexer')\n",
    "stages += [labelIndexer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5802c6da-13c2-4f95-b1fe-1b3689b7106a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = ['N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall']\n",
    "for num in num_features:\n",
    "    num_assembler = VectorAssembler(inputCols=[num], outputCol=num+'_vector')\n",
    "    num_scaler = StandardScaler(inputCol=num_assembler.getOutputCol(), outputCol=num+'_scaled')\n",
    "    stages += [num_assembler, num_scaler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92d8c2da-84be-4fd1-a075-82dce5358046",
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler_input = [num+'_scaled' for num in num_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ff20a499-d32e-4cc0-91bc-6a5174e66b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(\n",
    "    inputCols= assembler_input,\n",
    "    outputCol= 'feature_vector'\n",
    ")\n",
    "stages += [assembler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d581ab9-1c8e-4979-9671-6c7ad41536f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "pipeline = Pipeline(stages=stages)\n",
    "fitted_transform = pipeline.fit(train_data)\n",
    "vtrain_data = fitted_transform.transform(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ceecdb8b-f8e0-46c7-9edf-2a2645404b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(featuresCol='feature_vector', labelCol='labelIndexer')\n",
    "lr_model = lr.fit(vtrain_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2110f104-84b8-440d-8167-5e617242cd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "vtest_data = fitted_transform.transform(test_data)\n",
    "pred = lr_model.transform(vtest_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "37702227-d1f4-4545-9290-a046b711b26c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+\n",
      "|labelIndexer|prediction|\n",
      "+------------+----------+\n",
      "|         4.0|       4.0|\n",
      "|         7.0|       7.0|\n",
      "|         7.0|       7.0|\n",
      "|        15.0|      15.0|\n",
      "|        20.0|      20.0|\n",
      "+------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred.select('labelIndexer', 'prediction').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f505cc70-074b-46fe-bafd-8810a1b0e5ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import expr\n",
    "comp = pred.withColumn('correct', expr('case when labelIndexer = prediction then 1 else 0 end'))\n",
    "comp.where('correct=0').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7ee0e7b3-ae62-4c19-a1e2-df29bd6a5a93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9803063457330415"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp.selectExpr('avg(correct) as accuracy').collect()[0]['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "07ff165b-3934-40a2-9e42-2ab785a34f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lentil : 1.0\n",
      "maize : 1.0\n",
      "orange : 1.0\n",
      "grapes : 1.0\n",
      "mango : 1.0\n",
      "muskmelon : 1.0\n",
      "pomegranate : 1.0\n",
      "coconut : 1.0\n",
      "jute : 0.9\n",
      "cotton : 1.0\n",
      "papaya : 0.9523809523809523\n",
      "rice : 0.9047619047619048\n",
      "banana : 1.0\n",
      "chickpea : 0.9090909090909091\n",
      "pigeonpeas : 1.0\n",
      "kidneybeans : 1.0\n",
      "blackgram : 0.9583333333333334\n",
      "coffee : 1.0\n",
      "mungbean : 1.0\n",
      "watermelon : 1.0\n",
      "apple : 1.0\n",
      "mothbeans : 0.9642857142857143\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import max\n",
    "max_index = vtrain_data.select(max('labelIndexer')).collect()[0][0]\n",
    "for i in range(int(max_index) + 1):\n",
    "    acc = comp.filter(col('labelIndexer') == i).selectExpr('avg(correct) as accuracy').collect()[0]['accuracy']\n",
    "    crop_name = vtrain_data.select('label').filter(col('labelIndexer') == i).collect()[0][0]\n",
    "    print(f'{crop_name} : {acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "da5d964f-425d-451c-bcab-a54c008a2a13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, avg, stddev\n",
    "mean_val = df.select(avg(\"ph\")).collect()[0][0]\n",
    "stddev_val = df.select(stddev(\"ph\")).collect()[0][0]\n",
    "\n",
    "# 2. Z-score 임계값 설정\n",
    "threshold = 3.0\n",
    "\n",
    "\n",
    "drop_count = df.filter(\n",
    "    (col(\"ph\") < (mean_val - threshold * stddev_val)) |\n",
    "    (col(\"ph\") > (mean_val + threshold * stddev_val))\n",
    ").count()\n",
    "# 3. 이상치 제거\n",
    "df_no_outliers_zscore = df.filter(\n",
    "    (col(\"ph\") >= (mean_val - threshold * stddev_val)) &\n",
    "    (col(\"ph\") <= (mean_val + threshold * stddev_val))\n",
    ")\n",
    "drop_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "691283a5-18df-472f-b67a-f28d6db6b913",
   "metadata": {},
   "outputs": [],
   "source": [
    "ztrain_data, ztest_data = df_no_outliers_zscore.randomSplit([0.8,0.2], seed=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "54d8ff5e-05cd-4798-b9f4-ae3f84156fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=stages)\n",
    "fitted_transform = pipeline.fit(ztrain_data)\n",
    "vztrain_data = fitted_transform.transform(ztrain_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ad26b68e-7cc1-4ef1-a104-85eab2b34648",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(featuresCol='feature_vector', labelCol='labelIndexer')\n",
    "lr_model = lr.fit(vztrain_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "37bc4b3c-748f-45fc-b914-42c4573a67d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vztest_data = fitted_transform.transform(ztest_data)\n",
    "zpred = lr_model.transform(vztest_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "34300886-4b75-4b96-a0d3-8734eb20d35a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+\n",
      "|labelIndexer|prediction|\n",
      "+------------+----------+\n",
      "|         6.0|       6.0|\n",
      "|         5.0|       5.0|\n",
      "|         5.0|       5.0|\n",
      "|         3.0|       3.0|\n",
      "|         7.0|       7.0|\n",
      "+------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "zpred.select('labelIndexer', 'prediction').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2a7ba5cf-2794-4edb-add3-eb6a9b979457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import expr\n",
    "zcomp = zpred.withColumn('correct', expr('case when labelIndexer = prediction then 1 else 0 end'))\n",
    "zcomp.where('correct=0').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "11a4e4e1-4d2d-4c67-8343-425758a93ae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9889380530973452"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zcomp.selectExpr('avg(correct) as accuracy').collect()[0]['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "19a73f31-6b5a-4a65-87ab-a2b7d1470f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lentil : 1.0\n",
      "maize : 1.0\n",
      "grapes : 1.0\n",
      "kidneybeans : 1.0\n",
      "rice : 0.9444444444444444\n",
      "coconut : 1.0\n",
      "mango : 1.0\n",
      "apple : 1.0\n",
      "banana : 1.0\n",
      "blackgram : 0.9523809523809523\n",
      "pomegranate : 1.0\n",
      "watermelon : 1.0\n",
      "cotton : 1.0\n",
      "papaya : 1.0\n",
      "coffee : 1.0\n",
      "jute : 0.875\n",
      "mungbean : 1.0\n",
      "muskmelon : 1.0\n",
      "orange : 1.0\n",
      "pigeonpeas : 1.0\n",
      "chickpea : 1.0\n",
      "mothbeans : 1.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(int(max_index) + 1):\n",
    "    acc = zcomp.filter(col('labelIndexer') == i).selectExpr('avg(correct) as accuracy').collect()[0]['accuracy']\n",
    "    crop_name = vztrain_data.select('label').filter(col('labelIndexer') == i).collect()[0][0]\n",
    "    print(f'{crop_name} : {acc}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
